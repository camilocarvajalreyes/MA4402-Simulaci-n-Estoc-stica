\vspace{0.3cm}
\begin{center}
{\huge \textbf{Descenso de gradiente estocástico y aplicaciones}}
\end{center}

\subsection*{Problema 1: Redes Neuronales}
El objetivo de este problema es explorar el uso de una biblioteca de aprendizaje profundo. Más precisamente, implementaremos modelos de redes neuronales para clasificar imágenes usando la biblioteca \textit{PyTorch}. Para esto usaremos la base de datos \textit{MNIST}, que consiste en dígitos escritos a mano. La tarea consiste en entrenar un modelo que identifique de manera automática el dígito en cuestión. Para importar el conjunto, se debe descargar el archivo \textit{mnist.pkl.gz} y ejecutar el siguiente código.

\begin{verbatim}
    import pickle
    import gzip
    
    with gzip.open('data/mnist.pkl.gz', "rb") as f:
            ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding="latin-1")
\end{verbatim}

Un \textbf{Tensor} en el contexto de aprendizaje de máquinas, corresponde a la generalización de una matriz a dimensiones más altas, similar al concepto de arreglo de bibliotecas como \textit{numpy}. \textit{PyTorch} utiliza tensores para las computaciones, con la característica especial de que poder operarlos de manera rápida usando GPUs.

\begin{verbatim}
    import torch

    x_train, y_train, x_valid, y_valid = map(torch.tensor, (x_train, y_train, x_valid, y_valid))
    n, d = x_train.shape;
\end{verbatim}

El primer objetivo será definir un modelo que conste de una sola capa lineal, lo cual equivale a una regresión logística si le aplicamos la función \textit{softmax}. Definimos los parámetros de nuestra regresión como tensores, los cuales serán después optimizados. A modo de ejemplo, mostramos el resultado de darle un "mini-batch" a los parámetros de nuestro modelo no entrenado.

\begin{verbatim}
    import math

    pesos = torch.randn(784, 10) / math.sqrt(784)
    pesos.requires_grad_()
    sesgo = torch.zeros(10, requires_grad=True)
    
    batch_size = 64
    x_batch = x_train[0:batch_size]
    preds = x_batch @ pesos + sesgo
\end{verbatim}

\textit{PyTorch} guarda la información de los pasos aplicados a tensores. Esto se usa posteriormente para computar los gradientes para cada parámetro, los cuales se usarán en Descenso de Gradiente. Este método se llama Diferenciación Automática.

\newp Necesitamos definir una función de pérdida a minimizar. Esta sección se concentrará en justificar el uso de la función de pérdida entropía cruzada.

\newp Nos gustaría ajustar los parámetros de tal forma que la distribución de probabilidad dada por la red se asemeje lo más posible a la real distribución de los datos. Como solo tenemos observaciones de estos datos, para lo anterior buscaremos el estimador de máxima verosimilitud. Por ende queremos maximizar

$$ \prod^N_{i=1}p_\theta(y^{(i)}|x^{(i)})$$

donde $y^{(i)}\in\{c_1,\dots,c_k\}$ (las clases posibles) y $\theta$ son los parámetros de la red, que a su vez computa $p_\theta(c_j|x)$ en un paso \textit{forward} dado un punto de dato $x$. En otras palabras

$$ \hat\theta = \argmax_\theta \prod^N_{i=1}p_\theta(y^{(i)}|x^{(i)}) $$

\begin{enumerate}
	% \setcounter{enumi}{1}
	\item[1.a] Justifique que
    $$ \hat\theta = \argmax_\theta \frac{1}{N} \sum^N_{i=1} log(P_\theta(y^{(i)}|x^{(i)})) $$
\end{enumerate}

Sean $p$ y $q$ dos distribuciones de probabilidad discreta. La \textbf{entropía cruzada} está dada por 

$$ H(p,q) = \sum_x p(x) log(\frac{1}{q(x)})) \,.$$

Se define entonces la función de pérdida de entropía cruzada por

$$ L(q,p) = \frac{1}{N}\sum^N_{i=1}H(p_i,q_i) $$

\begin{enumerate}
	\item[1.b] Demuestre que
    $$ \hat\theta = \argmin_\theta L(p_\theta,p)$$
    donde $p$ es la distribución de probabilidad empírica.
\end{enumerate}

La función de pérdida de entropía cruzada puede ser accedida en \textit{PyTorch} mediante:

\begin{verbatim}
    import torch.nn.functional as F

    func_costo = F.cross_entropy
    print(func_costo(x_valid @ pesos + sesgo,y_valid).item())
\end{verbatim}

\begin{enumerate}
	\item[2.a] Complete el siguiente código que implementa \textbf{Descenso de Gradiente Mini-batch} para ajustar los parámetros del modelo dada una tasa de aprendizaje.
	\begin{verbatim}
	    def DescensoGradiente(pesos,sesgo,tasa):
            perdidas_epoch = []
            for i in range():
                # rellenar
                loss.backward()
                with torch.no_grad():
                    pesos -= pesos.grad * tasa
                    sesgo -= sesgo.grad * tasa
                    pesos.grad.zero_()
                    sesgo.grad.zero_()
                perdidas_epoch.append(loss.item())
            return perdidas_epoch
    \end{verbatim}
    \item[2.b] Implemente una función entrenar que tome un número de épocas y ejecute el método anterior en cada iteración, imprimiendo el valor de la función de pérdida. Guarde además estas pérdidas en una lista.
    \item[2.c] Ejecute el bucle para K épocas y grafique lo encontrado.
	
\end{enumerate}

La biblioteca \textit{PyTorch} nos provee de variadas herramientas que pueden ser útiles para el entrenamiento. Una de ellas es el módulo \href{https://pytorch.org/docs/stable/distributions.html}{torch.distributions}. Esta nos provee de algunas variables aleatorias conocidas de las cuales podemos samplear. Por ejemplo, para samplear de una distribución Gaussiana de dimensión 10, centrada en cero y con diagonal $=I$ ejecutamos:
\begin{verbatim}
    from torch.distributions import MultivariateNormal

    normal = MultivariateNormal(torch.zeros(2), torch.eye(2))
    normal.sample()
\end{verbatim}

\begin{itemize}
    \item[3] Usando esto, implemente la variante \textbf{Langevin Dynamics} del algoritmo de Gradiente Estocástico. Re-defina los parámetros del modelo y ajústelos usando esta variante. Grafique y comente. ¿Que desventajas puede tener usar este método para optimizar otros modelos?

    Observación: le puede ser útil el método \textit{.reshape()}, que funciona para tensores del mismo modo que para arreglos de numpy. 
\end{itemize}

A continuación se implementaremos lo anterior pero con el procedimiento usual que se usa en \textit{PyTorch}. Necesitamos definir nuestro modelo como una clase, que heredará atributos de la clase \textit{torch.nn.Module}. En \textit{torch.nn} podemos encontrar numerosos "bloques" para armar modelos. En este caso, simplemente usamos una capa lineal.

\newp Una parte esencial de nuestro modelo es el paso \textit{forward}, que será aquel que se ejecute cuando llamemos a nuestro modelo en uno o varios puntos de datos. Para más detalles ver \href{https://pytorch.org/docs/stable/nn.html}{la documentación}.

\begin{verbatim}
    from torch import nn

    class Reg_Logistica(nn.Module):
        def __init__(self):
            super().__init__()
            self.lineal = nn.Linear(784, 10)
    
        def forward(self, xb):
            return self.lineal(xb)
\end{verbatim}

Además, usamos el módulo \href{https://pytorch.org/docs/stable/optim.html}{torch.optim} para entrenar las redes, lo cual hace más consciso el código de gradiente estocástico escrito anteriormente.

\begin{verbatim}
    from torch import optim

    modelo = Reg_Logistica()
    opt_SGD = optim.SGD(modelo.parameters(), lr=learning_rate)
\end{verbatim}

\begin{itemize}
    \item[4] En base a lo anterior, re-defina el método entrenar para que tome un optimizador del módulo \textit{optim}, un modelo (sin entrenar) y un número de epocas. Ejecute el método con Descenso de Gradiente y grafique. Escoja dos métodos más del módulo \textit{optim}, entrene modelos con ellos y compare.
    \item[5] Re-defina el modelo usando una capa intermedia. Entrenelo usando alguna de los optimizadores. ¿Cómo se comparan los resultados de esta nueva red en ambos conjuntos con los modelos anteriores? Justifique.
\end{itemize}

\section*{Problema 2: Regresión Lineal}

Dado un conjunto de datos $(x_i,y_i)_{i=1}^n\subset\mathbb{R}^m\times\mathbb{R}$, se propone la siguiente relación entre sus componentes
\begin{equation}\label{reglin}
  y = \theta^Tx + \varepsilon,
\end{equation}
en donde $\varepsilon$ es una variable aleatoria con valor esperado 0 y distribución desconocida. El problema de regresión lineal consiste en encontrar el parámetro $\theta$ tal que el conjunto de datos satisfaga \eqref{reglin} de manera tal que $\mathrm{Var}(\varepsilon)$ sea lo más pequeña posible. Esto conlleva al problema de optimización
\[ \hat{\theta} = \arg\,\min_{\theta} \mathrm{Var}(\varepsilon) = \arg\,\min_{\theta}\mathbb{E}\left((y-\theta^Tx)^2\right).\]

El objetivo de esta pregunta es aplicar el modelo anterior sobre el conjunto de datos \textbf{Boston Housing Prices} y estimar el mejor parámetro posible utilizando el método de descenso de gradiente estocástico. 
\begin{enumerate}
    \item Cargue el conjunto de datos utilizando el siguiente código:
      \begin{verbatim}
        from sklearn.datasets import load_boston
        import pandas as pd
        
        data = load_boston()
        df = pd.DataFrame(data.data, columns = data.feature_names)
        df['PRICE'] = data.target
    \end{verbatim}
    
    Observe la cantidad de variables y el tipo de datos que posee. Normalice los datos para que el modelo a trabajar funcione. Extienda la base de datos para obtener un modelo de regresión lineal, esta vez representado por una función afín de la forma $y_i = \theta^Tx_i + b + \varepsilon_i$, con $\theta\in \mathbb{R}^m,\,b\in \mathbb{R}$.
\end{enumerate}

\begin{enumerate}    
    \item[2.] Separe los datos en un conjunto de entrenamiento y otro de prueba según la proporción 80\% y 20\%, para esto le será útil la función \texttt{train\_test\_split} de la librería \texttt{sklearn}. Justifique brevemente por qué esto es necesario.
\end{enumerate}

En lo que sigue justifique sus respuestas graficando la función de costos cada cierta cantidad de iteraciones. Cuando se pida comparar diferentes implementaciones debe realizarlo en base al conjunto de datos de prueba y el error cuadrático medio incurrido con la estimación obtenida. Tanto la cantidad de iteraciones como los parámetros pueden ser escogidos libremente.
\begin{enumerate}
  \item[3.] Implemente el algoritmo de descenso de gradiente estocástico para un modelo de regresión lineal, especificando cuál es la función de costos y su gradiente. Considere los siguientes casos
    \begin{enumerate}
      \item \emph{Learning rates} constantes.
      \item \emph{Learning rates} variables (proponga al menos 2).
    \end{enumerate}
    Proponga al menos dos en cada caso. Compare los resultados obtenidos para cada elección ¿Cuál es la mejor elección?
   
  \item[4.] Modifique el algoritmo anterior para trabajar con \emph{mini-batch}. Pruebe el desempeño (nuevamente en términos del error cuadrático medio para el conjunto de prueba) del algoritmo para distintos tamaños de \emph{mini-batch} y \emph{learning rates} y justifique cual es el mejor ¿Existe alguna relación entre ambos parámetros?
    
  \item[5.] Implemente las siguientes variantes de descenso de gradiente estocástico y compare el desempeño de estos con los algoritmos implementados en las partes anteriores
    \begin{enumerate}
        \item \textbf{Momentum:} El método consiste en ir generando los pasos de descenso como
          \[m_{i} = \beta m_{i-1} + (1-\beta)\nabla_{\theta}f(\theta_i,x_{i}),\hspace{0.4cm}m_0 = 0, \]
        tal que
        \[\theta_{i+1} = \theta_i -\eta\, m_i,\]
        donde $\beta\in(0,1)$ (debe ser elegido).
      \item \textbf{Adagrad:} El \emph{learning rate} es variable y se genera de la siguiente manera:
          \[\eta_{i} = \frac{\eta}{\sqrt{v_{i
          } + c}}, \]
        donde $c>0$, $\eta>0$ y 
        \begin{align*}
          v_{i} ={}& \sum_{j = 1}^{i}\|\nabla_{\theta}f(\theta_j,x_j)\|^2, \hspace{0.3cm}v_0 = 0.\\
        \end{align*}
    \end{enumerate}
    
\end{enumerate}

\iffalse
\section*{Problema 3: Regresi\'on log\'istica con gradiente estocástico }

En este problema aplicaremos el algoritmo de descenso de gradiente estocástico a un m\'etodo de clasificación supervisada denominado {\bf regresi\'on log\'istica}.  Consideramos un conjunto de $M$ datos correspondiente a vectores   $\{x^{(m)}\}_{i=1,\dots,M} \subset \mathbb{R}^p$ de caracter\'isticas,  y  sus respectivas etiquetas  $\{y^{(m)}\}_{i=1,\dots,M} \subset \{0,1\}$ que indican si cada uno de ellos pertenece a  una de dos ``clases''  posibles $C_0$ ó $C_1$. El objetivo es usar estos datos para aprender como clasificar correctamente cualquier vector nuevo $x$ de caracter\'isticas  en una de las clases $C_k$, $k=0,1$ (sin ver su etiqueta).

Por simplicidad nos restringiremos a modelos de clasificación lineales, los que pueden escribirse de manera general como
\[  \phi(x)=\sigma\left( \langle a, x\rangle + b  \right), \]
donde  $x\in \mathbb{R}^p$, $a\in \mathbb{R}^p$  y $b\in \mathbb{R}$ son par\'ametros fijos,  y $\sigma: \mathbb{R}\to [0,1]$ es una función ``de activación'', creciente, no lineal, fija,  que se usar\'a para atribuir el vector $x$ a la clase $C_1$ o $C_0$ seg\'un si el valor de $\phi$ est\'a por encima o debajo de un cierto umbral (por ejemplo, etiquetar $x$ como de clase $C_1$ si $\phi(x)=\sigma   ( a^\mathrm{t}x + b) \in (1/2, 1]$, y de clase $C_0$ en caso contrario).  
 Para simplificar la notación introducimos la  escritura
\[  \sigma(w^\mathrm{t}x) =  \sigma\left( \langle a, x \rangle+ b  \right), \]
donde  $w = (a,b)\in \mathbb{R}^{p+1}$ y, con abuso de notaci\'on, $x$ en el lado izquierdo corresponde  al vector agrandado $ (x,1)\in\mathbb{R}^{p+1}$.  Puesto que $\sigma(w^\mathrm{t}x)\in (0,1)$ podemos pensar  intuitivamente en esta cantidad como  ``probabilidad'' de que un vector de caracter\'isticas aleatorias  $x$  provenga de la clase $C_1$.  

Escogeremos como $\sigma$ la llamada función logística o sigmoide: 
\[ \phi(r)=\sigma(r) = \frac{1}{1+e^{-r}}. \]


\begin{enumerate}
\item  Dado un dato $x$,  interprete geom\'etricamente la condici\'on $\sigma(w^\mathrm{t}x)\in (1/2,1]$. 

  Veamos  ahora que la intepretaci\'on probabilista antes mecionada es rigurosa para el caso de un modelo Bayesiano  en que los datos son generados por dos posibles leyes Gaussianas multivariadas. De manera m\'as precisa supongamos que, condicionalmente a que el dato $x$ proviene de la clase  $C_i$, $i\in\{0,1\}$, se tiene que $  x\sim {\cal N}( \mu_i , \Sigma)$ normal multivariada en $\mathbb{R}^p$ de media $\mu_i$ y  varianza-covarianza no singular $\Sigma$ (igual para ambas clases).  Supongamos adem\'as que cada dato proviene de una clase $C_i$, que tiene probabilidad a priori $p(C_i)\in (0,1)$ de ser elegida para generar ese dato.  Explicite $p(x\vert C_i)$  para $i=0,1$ y muestre que $p(C_1\vert x)$ esta dada por
  \[ p(C_1\vert x)=  \sigma (w^\mathrm{t}x )= \frac{1}{1+ \exp{(-\langle a, x\rangle - b)}}, \]
  con
  \[ a= \Sigma^{-1}(\mu_1-\mu_0)\mbox{ y } b= \frac{1}{2} (\mu_0^\mathrm{t}  \Sigma^{-1} \mu_0 - \mu_1^\mathrm{t}  \Sigma^{-1} \mu_1)+ \ln\left(\frac{p(C_1)}{p(C_0)}\right).\]
 

  \item Supondremos en lo que sigue  que cada observación $(x^{(1)},y^{(1)}),\dots,(x^{(m)},y^{(m)})$ se obtiene de manera independientemente, sampleando,  {\it para cada una}, primero una clase $y^{(m)}\in \{0,1\}$ y luego un vector de caracter\'isticas $x^{(m)}$ aleatorias de datos de clase $C_{y^{(m)}}$. 
  Para encontrar el parámetro $w = (a,b)\in \mathbb{R}^{p+1} $ que mejor explica las etiquetas de los datos observados $(x^{(1)},y^{(1)}),\dots,(x^{(m)},y^{(m)})$, se propone maximizar la función de ``verosimilitud '' 
  \[ \prod_{m=1}^M \sigma\bigl( w^\mathrm{t}x^{(m)} \bigr)^{y^{(m)}} \Bigl( 1 - \sigma\bigl( w^\mathrm{t}x^{(m)}\bigr) \Bigr)^{(1-y^{(m)})}, \]
  lo cual es equivalente a minimizar la función de pérdida
  \begin{equation}\label{LogLike}
     L(w) = -\frac{1}{M}\sum_{m=1}^My^{(m)}\log \sigma\bigl(w^\mathrm{t}x^{(m)}\bigr) + (1-y^{(m)})\log\Bigl(1-\sigma\bigl(w^\mathrm{t}x^{(m)}\bigr)\Bigr). 
   \end{equation}
   En el caso de la parte 1, d\'e una interpretaci\'on de  esta funci\'on en t\'erminos de verosimilitudes ``a posteriori'' y explique por qu\'e tiene sentido buscar maximizarla.   Encuentre adem\'as (en general) una expresi\'on simple para la derivada con respecto a $w$ de cada uno de los t\'erminos de la suma.  
   \item Proponga e implemente un algoritmo de descenso de gradiente estocástico,  para resolver numéricamente el problema de minimización
    \[ \min_w L(w).\]
                
    Genere $4000$ datos  ``de entrenamiento'' etiquetados de dos clases Gaussianas  en $\mathbb{R}^2$ como en la parte 1,  equiprobables, para  cada una de 2 elecciones  fijas de par\'ametros $(\mu_0,\mu_1)$ (correspondiente a distintos grados de separaci\'on de las Gaussianas).  
    
    Utilice el algoritmo para encontrar  el hiperplano  que mejor separa las dos Gaussianas en cada caso. Para el paso considere varias sucesiones del estilo  $\gamma_t = \frac{\gamma_0}{1+t/t_0}$, con  distintos valores de par\'ametros (por ejemplo $t_0 = 100$ y $\gamma_0 = 0.05$).  
    Para cada conjunto de datos y grado de separaci\'on, corra el algoritmo varias veces desde  varias  condiciones iniciales  distintas ¿C\'omo influyen estas en el resultado? Compare los resultados obtenidos con el  hiperplano $w$ ``te\'orico '' para esas Gaussianas. Grafique los hiperplanos obtenidos junto con (parte de) las nubes de datos.  En cada caso, guarde la trayectoria de puntos  $w_t$ generados por el algoritmo.  
  
  \item Considere ahora un caso de  Gaussianas  "poco separadas".  Fije una elecci\'on de condici\'on inicial entre las consideradas  en la parte anterior.  Corra el algoritmo con  \emph{mini-batchs} de  tama\~nos  distintos. Grafique en cada caso la evoluci\'on de los valores de la funci\'on que se minimiza, y comente las diferencias  observadas con distintos pasos y tamaños. 

    Discuta la rapidez de convergencia del algoritmo, la influencia del paso elegido y del tama\~no del \emph{mini-batch}.  
   
   Finalmente, para  cada uno los conjuntos de datos considerados en esta parte,  genere ahora $1000$ datos adicionales ``de  prueba''.  Cuantifique el error de generalizaci\'on (o ``fuera de muestra'') de la estimaci\'on realizada, usando la log-verosimilitud como funci\'on de $w$, calculada con estos nuevos datos.  Muestre gr\'aficamente como mejora ese error de generalizaci\'on  a medida que $w_t$ evoluciona hasta el valor final obtenido con el algoritmo.  
   
 \item Aplique ahora regresi\'on logística para clasificar  tumores de mama, en las clases ``benigno'' o ``maligno'',  usando los datos provistos en Material Docente (\texttt{data.csv}\footnote{Fuente: \url{https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+\%28Diagnostic\%29}}). Para ello estandarice cada una de las columnas de datos y entrene el algoritmo antes implementado con el $80\%$ de los datos.  Use despu\'es el $20\%$ restante para  evaluar como generaliza el clasificador encontrado con regresi\'on log\'istica . 
\end{enumerate}
\fi