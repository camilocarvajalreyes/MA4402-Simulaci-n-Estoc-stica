{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 4.1 - Descenso de gradiente estocástico y aplicaciones\n",
    "\n",
    "MA4402 - Simulación Estocástica: Teoría y Laboratorio\n",
    "\n",
    "Profesor: Joaquín Fontobona T.\n",
    "\n",
    "Auxiliares: Pablo Zúñiga Rodríguez-Peña, Arie Wortsman Z., Camilo Carvajal Reyes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grupo N**\n",
    "\n",
    "**Integrantes:**\n",
    "\n",
    "- Integrante 1\n",
    "- Integrante 2\n",
    "- Integrante 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problema 1 - Regresión Lineal\n",
    "\n",
    "Dado un conjunto de datos $(x_i,y_i)_{i=1}^n\\subset\\mathbb{R}^m\\times\\mathbb{R}$, se propone la siguiente relación entre sus componentes\n",
    "$$  y = \\theta^Tx + \\varepsilon\\,,$$\n",
    "en donde $\\varepsilon$ es una variable aleatoria con valor esperado 0 y distribución desconocida. El problema de regresión lineal consiste en encontrar el parámetro $\\theta$ tal que el conjunto de datos satisfaga la ecuación anterior, de manera tal que $\\mathrm{Var}(\\varepsilon)$ sea lo más pequeña posible. Esto conlleva al problema de optimización\n",
    "$$ \\hat{\\theta} = \\arg\\,\\min_{\\theta} \\mathrm{Var}(\\varepsilon) = \\arg\\,\\min_{\\theta}\\mathbb{E}\\left((y-\\theta^Tx)^2\\right)\\,.$$\n",
    "\n",
    "El objetivo de esta pregunta es aplicar el modelo anterior sobre el conjunto de datos **Diabetes** y estimar el mejor parámetro posible utilizando el método de descenso de gradiente estocástico. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1.a - Cargue el conjunto de datos utilizando el siguiente código. Observe la cantidad de variables y el tipo de datos que posee. ¿Que complicaciones pueden surgir de usar un modelo predictivo en un contexto real? Reflexione acerca de la naturaleza del dataset y la tarea que se quiere ejecutar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "df, target = load_diabetes(return_X_y=True,as_frame=True)\n",
    "print(load_diabetes().DESCR)\n",
    "print(\"Target variable statistcs:\\n\"+str(target.describe()))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos referimos a estandarizar cuando forzamos los datos a tener una distribución normal estándar. Para esto, reemplazamos cada punto de dato $x_i$ por:\n",
    "\n",
    "$$ \\tilde x_i = \\frac{x_i-\\mu}{\\sigma}$$\n",
    "\n",
    "En donde $\\mu$ es la media de la columna y $\\sigma$ es su desviación estándar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1.b - Estandarice los datos (sin usar funciones de pre-procesamiento) para que el modelo a trabajar funcione. Extienda la base de datos (agregando una columna) para obtener un modelo de regresión lineal, esta vez representado por una función afín de la forma $y_i = \\theta^Tx_i + b + \\varepsilon_i$, con $\\theta\\in \\mathbb{R}^m,\\,b\\in \\mathbb{R}$.\n",
    "\n",
    "Nota: no estandarice la columna objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1.c - Separe los datos en un conjunto de entrenamiento y otro de prueba según la proporción 80\\% y 20\\%,  Justifique brevemente por qué esto es necesario. Le será útil la función siguiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En lo que sigue justifique sus respuestas graficando la función de costos cada cierta cantidad de iteraciones. Cuando se pida comparar diferentes implementaciones debe realizarlo en base al conjunto de datos de prueba y el error cuadrático medio incurrido con la estimación obtenida. Tanto la cantidad de iteraciones como los parámetros pueden ser escogidos libremente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 2 - Implemente el algoritmo de descenso de gradiente estocástico para un modelo de regresión lineal, especificando cuál es la función de costos y su gradiente. Considere los siguientes casos\n",
    "-  _Learning rates_ constantes.\n",
    "-  _Learning rates_ variables (proponga al menos 2).\n",
    "\n",
    "> Proponga al menos dos en cada caso. Compare los resultados obtenidos para cada elección ¿Cuál es la mejor elección?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 3 - Modifique el algoritmo anterior para trabajar con _mini-batch_. Pruebe el desempeño (nuevamente en términos del error cuadrático medio para el conjunto de prueba) del algoritmo para distintos tamaños de _mini-batch_ y _learning rates_ y justifique cual es el mejor ¿Existe alguna relación entre ambos parámetros?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 4 - Implemente las siguientes variantes de descenso de gradiente estocástico y compare el desempeño de estos con los algoritmos implementados en las partes anteriores\n",
    "- **Momentum:** El método consiste en ir generando los pasos de descenso como\n",
    "\n",
    "$$ m_{i} = \\beta m_{i-1} + (1-\\beta)\\nabla_{\\theta}f(\\theta_i,x_{i}),\\, m_0 = 0\\,, $$\n",
    "\n",
    "tal que\n",
    "\n",
    "$$\\theta_{i+1} = \\theta_i -\\eta\\, m_i\\,,$$\n",
    "\n",
    "donde $\\beta\\in(0,1)$ (debe ser elegido).\n",
    "\n",
    "- **Adagrad:** El _learning rate_ es variable y se genera de la siguiente manera:\n",
    "\n",
    "$$\\eta_{i} = \\frac{\\eta}{\\sqrt{v_{i} + c}}, $$\n",
    "\n",
    "donde $c>0$, $\\eta>0$ y \n",
    "\n",
    "$$ v_{i} ={} \\sum_{j = 1}^{i}\\|\\nabla_{\\theta}f(\\theta_j,x_j)\\|^2 \\text{ , }\\, v_0 = 0\\,.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 5 (bonus) - Realice una búsqueda de grilla (_gridsearch_) para escoger los mejores hiperparámetros para Momentum y Adagrad. Dado un batch size $m$, reporte los errores del test set en un mapa de calor para valores de $\\beta$ y $\\nu$ (respectivamente $c$ y $\\nu$) de su elección. Repita para otro valor de $m$. Describa los resultados y concluya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 2 - Redes Neuronales\n",
    "\n",
    "El objetivo de este problema es explorar el uso de una biblioteca de aprendizaje profundo. Más precisamente, implementaremos modelos de redes neuronales para clasificar imágenes usando la biblioteca _PyTorch_. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esto usaremos la base de datos _MNIST_, que consiste en dígitos escritos a mano. La tarea consiste en entrenar un modelo que identifique de manera automática el dígito en cuestión. Para importar el conjunto, se debe descargar el archivo `mnist.pkl.gz` y ejecutar el siguiente código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "\n",
    "with gzip.open('data/mnist.pkl.gz', \"rb\") as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(x_train[0].reshape((28, 28)), cmap=\"gray\")\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un **Tensor** en el contexto de aprendizaje de máquinas, corresponde a la generalización de una matriz a dimensiones más altas, similar al concepto de arreglo de bibliotecas como _numpy_. _PyTorch_ utiliza tensores para las computaciones, con la característica especial de que poder operarlos de manera rápida usando GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x_train, y_train, x_valid, y_valid = map(torch.tensor, (x_train, y_train, x_valid, y_valid))\n",
    "n, d = x_train.shape;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El primer objetivo será definir un modelo que conste de una sola capa lineal, lo cual equivale a una regresión logística si le aplicamos la función _softmax_. Definimos los parámetros de nuestra regresión como tensores, los cuales serán después optimizados. A modo de ejemplo, mostramos el resultado de darle un \"mini-batch\" a los parámetros de nuestro modelo no entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "pesos = torch.randn(784, 10) / math.sqrt(784)\n",
    "pesos.requires_grad_()\n",
    "sesgo = torch.zeros(10, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n",
      "tensor([-0.2377, -0.0996, -0.1152, -0.5616,  0.0341,  0.2325,  0.3503,  0.5375,\n",
      "        -0.3854, -0.6338], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "x_batch = x_train[0:batch_size]\n",
    "preds = x_batch @ pesos + sesgo\n",
    "print(preds.shape)\n",
    "print(preds[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notemos que en el output contiene una función de gradiente. Esto puesto a que _PyTorch_ guarda la información de los pasos aplicados a tensores. Esto se usa posteriormente para computar los gradientes para cada parámetro, los cuales se usarán en Descenso de Gradiente. Este método se llama Diferenciación Automática."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora necesitamos definir una función de pérdida a minimizar. Esta sección se concentrará en justificar el uso de la función de pérdida entropía cruzada.\n",
    "\n",
    "Nos gustaría ajustar los parámetros de tal forma que la distribución de probabilidad dada por la red se asemeje lo más posible a la real distribución de los datos. Como solo tenemos observaciones de estos datos, para lo anterior buscaremos el estimador de máxima verosimilitud. Por ende queremos maximizar\n",
    "\n",
    "$$ \\prod^N_{i=1}p_\\theta(y^{(i)}|x^{(i)})$$\n",
    "\n",
    "donde $y^{(i)}\\in\\{c_1,\\dots,c_k\\}$ (las clases posibles) y $\\theta$ son los parámetros de la red, que a su vez computa $p_\\theta(c_j|x)$ en un paso _forward_ dado un punto de dato $x$. En otras palabras\n",
    "\n",
    "$$ \\hat\\theta = \\arg \\max_\\theta \\prod^N_{i=1}p_\\theta(y^{(i)}|x^{(i)}) $$\n",
    "\n",
    "1.a - Justifique que\n",
    "\n",
    "$$ \\hat\\theta = \\arg \\max_\\theta \\frac{1}{N} \\sum^N_{i=1} log(P_\\theta(y^{(i)}|x^{(i)})) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sean $p$ y $q$ dos distribuciones de probabilidad discreta. La **entropía cruzada** está dada por \n",
    "\n",
    "$$ H(p,q) = \\sum_x p(x) log(\\frac{1}{q(x)})) \\,.$$\n",
    "\n",
    "Se define entonces la función de pérdida de entropía cruzada por\n",
    "\n",
    "$$ L(q,p) = \\frac{1}{N}\\sum^N_{i=1}H(p_i,q_i) $$\n",
    "\n",
    "1.b - Demuestre que\n",
    "\n",
    "$$ \\hat\\theta = \\arg \\min_\\theta L(p_\\theta,p)$$\n",
    "\n",
    "donde $p$ es la distribución de probabilidad empírica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.c - Comente brevemente la relación entre la entropía cruzada y la teoría de la información."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función de pérdida de entropía cruzada puede ser accedida en _PyTorch_ mediante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3304712772369385\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "func_costo = F.cross_entropy\n",
    "print(func_costo(x_valid @ pesos + sesgo,y_valid).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.a - Complete el siguiente código que implementa **Descenso de Gradiente Mini-batch** para ajustar los parámetros del modelo dada una tasa de aprendizaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DescensoGradiente(pesos,sesgo,tasa):\n",
    "    perdidas_epoch = []\n",
    "    # rellenar acá\n",
    "    cantidad_batches = None  # cambiar\n",
    "    # ------------\n",
    "    for i in range(cantidad_batches):\n",
    "        # rellenar acá\n",
    "        loss = None  # calcular pérdida\n",
    "        # ------------\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            pesos -= pesos.grad * tasa\n",
    "            sesgo -= sesgo.grad * tasa\n",
    "            pesos.grad.zero_()\n",
    "            sesgo.grad.zero_()\n",
    "        perdidas_epoch.append(loss.item())\n",
    "    return perdidas_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A una barrida completa al conjunto de entrenamiento se le llama época (o _epoch_ en inglés).\n",
    "\n",
    "2.b - Implemente una función `entrenar` que tome un número de épocas y ejecute el método anterior en cada iteración, imprimiendo el valor de la función de pérdida. Guarde además estas pérdidas en una lista,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2c - Ejecute el bucle para K épocas y grafique. Utilice otras métricas para evaluar la calidad de la clasificación, ¿que clases son más y menos fáciles de reconocer con el algoritmo? Le puede ser útil el [reporte de clasificación](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html) de scikit-learn y la siguiente función para obtener las predicciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logsoftmax = torch.nn.LogSoftmax(dim=0)\n",
    "\n",
    "def predicciones(output):\n",
    "    return torch.argmax(logsoftmax(output),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La biblioteca _PyTorch_ nos provee de variadas herramientas que pueden ser útiles para el entrenamiento. Una de ellas es el módulo [torch.distributions](https://pytorch.org/docs/stable/distributions.html). Esta nos provee de algunas variables aleatorias conocidas de las cuales podemos samplear. Por ejemplo, para samplear de una distribución Gaussiana de dimensión 10, centrada en cero y con diagonal $=I$ ejecutamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.0379, -0.1660])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.distributions import MultivariateNormal\n",
    "\n",
    "normal = MultivariateNormal(torch.zeros(2), torch.eye(2))\n",
    "normal.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 - Usando esto, implemente la variante **Langevin Dynamics** del algoritmo de Gradiente Estocástico. Re-defina los parámetros del modelo y ajústelos usando esta variante. Grafique y comente. ¿Que desventajas puede tener usar este método para optimizar otros modelos?\n",
    "\n",
    "Observación: le puede ser útil el método `.reshape()`, que funciona para tensores del mismo modo que para arreglos de numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se implementaremos lo anterior pero con el procedimiento usual que se usa en _PyTorch_. Necesitamos definir nuestro modelo como una clase, que heredará atributos de la clase _torch.nn.Module_. En _torch.nn_ podemos encontrar numerosos \"bloques\" para armar modelos. En este caso, simplemente usamos una capa lineal.\n",
    "\n",
    "Una parte esencial de nuestro modelo es el paso `forward`, que será aquel que se ejecute cuando llamemos a nuestro modelo en uno o varios puntos de datos.\n",
    "\n",
    "Para más detalles ver [la documentación](https://pytorch.org/docs/stable/nn.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Reg_Logistica(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lineal = nn.Linear(784, 10)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        return self.lineal(xb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además, usamos el módulo [torch.optim](https://pytorch.org/docs/stable/optim.html) para entrenar las redes, lo cual hace más consciso el código de gradiente estocástico escrito anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "modelo = Reg_Logistica()\n",
    "opt_SGD = optim.SGD(modelo.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez importado nuestro optimizador, no es necesario actualizar uno por uno nuestros parámetros, lo cual es particularmente útil cuando tenemos muchos (por ejemplo, en aprendizaje profundo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reemplazamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pesos -= pesos.grad * learning_rate\n",
    "    sesgo -= sesgo.grad * learning_rate\n",
    "    pesos.grad.zero_()\n",
    "    sesgo.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_SGD.step()\n",
    "opt_SGD.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.a - En base a lo anterior, re-defina el método entrenar para que tome un optimizador del módulo `optim`, un modelo (sin entrenar) y un número de epocas. Ejecute el método con Descenso de Gradiente y grafique. Escoja dos métodos más del módulo `optim`, entrene modelos con ellos y compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.b - Re-defina el modelo usando una capa intermedia. Entrenelo usando alguna de los optimizadores. ¿Cómo se comparan los resultados de esta nueva red en ambos conjuntos con los modelos anteriores? Justifique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 (bonus) - Un tipo de red neuronal que funciona bien para el procesamiento de imágenes son las **redes convolucionales (_CNN_)**. Averigue a que corresponde un **Núcleo (_Kernel_)** en procesamiento digital de imágenes y resuma en un parrafo. Investigue y mencione alguna ventaja de usar redes convolucionales. \n",
    "\n",
    "A continuación complete el siguiente código usando [redes convolucionales](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html) (en vez de capas lineales) y [ReLu](https://pytorch.org/docs/stable/generated/torch.nn.functional.relu.html) como no linealidad. Pruebe su red del mismo modo que antes y compare los resultados con las partes anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # defina acá dos o más transformaciones convolucionales\n",
    "        # considere kernel_size=3, stride=2, padding=1\n",
    "        # como mnist está en blanco y negro el número de canales del input es 1\n",
    "\n",
    "    def forward(self, xb):\n",
    "        xb = xb.view(-1, 1, 28, 28)\n",
    "        # transforme xb componiendo las capas convolucionales con relu\n",
    "        xb = F.avg_pool2d(xb, 4)\n",
    "        return xb.view(-1, xb.size(1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('simest')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "42064ca617cfb068adce3bd207e3274f2a938d52bdae7317c50bd6e6db102739"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
